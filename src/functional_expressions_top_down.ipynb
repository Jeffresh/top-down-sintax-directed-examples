{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit ('.env')",
   "display_name": "Python 3.8.6 64-bit ('.env')",
   "metadata": {
    "interpreter": {
     "hash": "adcabe18d460ae284ceb39d9db0204afe32efb4ddc49dfc6f81296d14619f755"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Functional expression notation\n",
    "\n",
    "Design of  the translation scheme (offset parameters Pascal style. That is, the parameters are put on the stack form left ro right) of this grammar using\n",
    "a top down analyzer\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Grammar:\n",
    "\n",
    "```\n",
    "Def -> Tipo ID Resto\n",
    "Resto -> ‘,’ Tipo ID Resto\n",
    "Resto -> epsilon\n",
    "Tipo -> INT\n",
    "Tipo -> CHAR\n",
    "Tipo -> FLOAT\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Entry example:\n",
    "\n",
    "**Input:**\n",
    "\n",
    "`f(int a, float b, char c)`\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Offset de c = 4\n",
    "Offset de b = 4 + sizeof(char)\n",
    "Offset de a = 4 + sizeof(char) + sizeof(float)\n",
    "\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## First and follow set\n",
    "\n",
    "First of all we have to get the first and the follow set that it will define our functions that represents the rules of the grammar"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### First set\n",
    "\n",
    "- First(Def) = {ID}\n",
    "- First(Resto) = {`','`, epsilon}\n",
    "- First(Tipo) = {INT, CHAR, FLOAT}\n",
    "\n",
    "### Follow set\n",
    "- Follow(Def) = {`$`}\n",
    "- Follow(Resto) = Follow(Resto) U Follow(Def) = {`$`}\n",
    "- Follow(Tipo) = {`ID`}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Lexer implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting sly\n",
      "  Using cached sly-0.4.tar.gz (60 kB)\n",
      "Using legacy 'setup.py install' for sly, since package 'wheel' is not installed.\n",
      "Installing collected packages: sly\n",
      "    Running setup.py install for sly: started\n",
      "    Running setup.py install for sly: finished with status 'done'\n",
      "Successfully installed sly-0.4\n",
      "WARNING: You are using pip version 20.2.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\los_g\\onedrive\\documentos\\pl\\pl-2020\\seminarios\\seminario_4\\top-down-sintax-directed-examples\\.env\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install sly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sly import Lexer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcLexer(Lexer):\n",
    "    tokens = {ID, CHAR, INTEGER, FLOAT}\n",
    "    ignore = ' \\t'\n",
    "    literals = {','}\n",
    "\n",
    "    # Regular expression rules for tokens\n",
    "\n",
    "    ID = r'[a-zA-Z_][a-zA-Z0-9_]*'\n",
    "    ID['char'] = CHAR\n",
    "    ID['integer'] = INTEGER\n",
    "    ID['float'] = FLOAT\n",
    "\n",
    "    @_(r'\\n+')\n",
    "    def newline(self, t):\n",
    "        self.lineno += t.value.count('\\n')\n",
    "\n",
    "    def error(self, t):\n",
    "        print('Illegal character {}'.format(t.value[0]))\n",
    "        self.index += 1\n",
    "\n",
    "tabla = {}\n",
    "ta = None\n",
    "ind = 0\n",
    "tokens = None\n",
    "tokenlist = None\n",
    "\n",
    "class Node():\n",
    "    def write():\n",
    "        pass\n",
    "\n",
    "class IntNode(Node):\n",
    "    def write():\n",
    "        return \"int\"\n",
    "\n",
    "class FloatNode(Node):\n",
    "    def write():\n",
    "        return \"float\"\n",
    "\n",
    "class CharNode(Node):\n",
    "    def write():\n",
    "        return \"char\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "type = 'ID', value = int\ntype = 'ID', value = a\ntype = ',', value = ,\ntype = 'ID', value = int\ntype = 'ID', value = b\ntype = ',', value = ,\ntype = 'ID', value = int\ntype = 'ID', value = c\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = 'int a, int b, int c'\n",
    "    lexer = CalcLexer()\n",
    "    for token in lexer.tokenize(data):\n",
    "        print(\"type = '{}', value = {}\".format(token.type, token.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definition():\n",
    "    global ta, tokens\n",
    "    if ta.type =="
   ]
  }
 ]
}